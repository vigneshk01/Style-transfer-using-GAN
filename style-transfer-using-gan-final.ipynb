{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer Using GAN (CycleGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables, Hyperparamaters and libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# PLATFORM = 'collab'\n",
    "PLATFORM = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy tensorflow matplotlib imageio scikit-image tensorboard\n",
    "# %pip install git+https://github.com/tensorflow/docs\n",
    "\n",
    "import os \n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "from skimage.io import imread \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLATFORM == 'collab':\n",
    "    SOURCE_FOLDER = '/content/drive/MyDrive/Colab Notebooks/projects/Style-Transfer-using-GAN/Source/'\n",
    "    T1_FOLDER = SOURCE_FOLDER + 'Tr1/TrainT1/'\n",
    "    T2_FOLDER = SOURCE_FOLDER + 'Tr2/TrainT2/'\n",
    "else:\n",
    "    SOURCE_FOLDER = './Source/'\n",
    "    T1_FOLDER = SOURCE_FOLDER + 'Tr1/TrainT1/'\n",
    "    T2_FOLDER = SOURCE_FOLDER + 'Tr2/TrainT2/'\n",
    "\n",
    "OUTPUT_FOLDER = './Output/'\n",
    "TIMESTAMP = str(time.strftime('%Y%m%d%H%M%S'))\n",
    "TEMP_FOLDER = OUTPUT_FOLDER + TIMESTAMP + '/'\n",
    "\n",
    "if os.path.exists(OUTPUT_FOLDER):\n",
    "    os.mkdir(TEMP_FOLDER)\n",
    "else:\n",
    "    os.mkdir(OUTPUT_FOLDER)\n",
    "    os.mkdir(TEMP_FOLDER)\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 4 #1 \n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and resize images\n",
    "def load_images(path, size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    images = glob.glob(path+'*.png')\n",
    "    data_list = list()\n",
    "\n",
    "    for filename in images:\n",
    "        pixels = load_img(filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store the data\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)\n",
    "\n",
    "t1_images = load_images(T1_FOLDER)\n",
    "t2_images = load_images(T2_FOLDER)\n",
    "\n",
    "tr1_data = tf.image.rgb_to_grayscale(t1_images)\n",
    "tr2_data = tf.image.rgb_to_grayscale(t2_images)\n",
    "\n",
    "print(tr1_data.shape)\n",
    "print(tr2_data.shape)\n",
    "\n",
    "tr1_dt= tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(tr1_data))\n",
    "tr2_dt= tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(tr2_data))\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(tr1_data[0], cmap='grey')\n",
    "axs[1].imshow(tr2_data[0], cmap='grey')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1_images = np.zeros((t1_df.shape[0], IMG_HEIGHT, IMG_WIDTH))\n",
    "# t2_images = np.zeros((t2_df.shape[0], IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "# for idx, img in enumerate(t1_df['img_pxl']):\n",
    "#     t1_images[idx, :, :] = resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "# for idx, img in enumerate(t2_df['img_pxl']):\n",
    "#     t2_images[idx, :, :] = resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "# t1_images.shape    \n",
    "# t2_images.shape\n",
    "\n",
    "# t1_images = (t1_images/127.5)-1.0\n",
    "# t2_images = (t2_images/127.5)-1.0\n",
    "\n",
    "# t1_images = t1_images.reshape(t1_images.shape[0], IMG_HEIGHT, IMG_WIDTH, 1).astype('float32')\n",
    "# t2_images = t2_images.reshape(t2_images.shape[0], IMG_HEIGHT, IMG_WIDTH, 1).astype('float32')\n",
    "\n",
    "# t1_img_data = tf.data.Dataset.from_tensor_slices(t1_images).shuffle(t1_images.shape[0], seed=42).batch(BATCH_SIZE)\n",
    "# t2_img_data = tf.data.Dataset.from_tensor_slices(t2_images).shuffle(t2_images.shape[0], seed=42).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Normalization, Shuffling and Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image =  tf.cast(image, tf.float32)\n",
    "    image= (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_image_train(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tr1 = tr1_dt.map(preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "tr2 = tr2_dt.map(preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# tr1 = tr1_dt.map(normalize, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# tr2 = tr2_dt.map(normalize, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "sample_t1_data = next(iter(tr1))\n",
    "sample_t2_data = next(iter(tr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation Tryouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulates thermal/electronic noise in scanners\n",
    "def add_gaussian_noise(image, mean=0.0, stddev=15.0):\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=mean, stddev=stddev, dtype=tf.float32)\n",
    "    noisy_image = tf.clip_by_value(image + noise, 0.0, 255.0)\n",
    "    return noisy_image\n",
    "\n",
    "# Mimics scanner calibration issues\n",
    "def intensity_shift(image, shift_range=30):\n",
    "    shift = tf.random.uniform([], -shift_range, shift_range, dtype=tf.float32)\n",
    "    shifted_image = image + shift\n",
    "    return tf.clip_by_value(shifted_image, 0.0, 255.0)\n",
    "\n",
    "\n",
    "#Simulates non-uniform magnetic field causing smooth illumination bias\n",
    "def intensity_gradient(image):\n",
    "    height, width, _ = image.shape\n",
    "    gradient = tf.linspace(0.8, 1.2, width)\n",
    "    gradient = tf.reshape(gradient, (1, width, 1))\n",
    "    biased_image = image * gradient\n",
    "    return tf.clip_by_value(biased_image, 0.0, 255.0)\n",
    "\n",
    "#MRI scans from different scanners may have varying contrast levels\n",
    "def random_contrast(image, lower=0.7, upper=1.3):\n",
    "    # Contrast variation in the range [0, 255]\n",
    "    contrast_factor = tf.random.uniform([], lower, upper)\n",
    "    contrast_image = image * contrast_factor\n",
    "    return tf.clip_by_value(contrast_image, 0.0, 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 5))\n",
    "\n",
    "axs[0][0].imshow(tr1_data[0], cmap=\"grey\")  # Original\n",
    "axs[0][0].set_title('Original T1')\n",
    "axs[0][1].imshow(add_gaussian_noise(tr1_data[0]), cmap=\"grey\")\n",
    "axs[0][1].set_title('Gaussian Noise')\n",
    "axs[0][2].imshow(intensity_gradient(tr1_data[0]), cmap=\"grey\")\n",
    "axs[0][2].set_title('Biased Magnetic Field')\n",
    "axs[0][3].imshow(random_contrast(tr1_data[0]), cmap=\"grey\")\n",
    "axs[0][3].set_title('Randomized Contrast')\n",
    "axs[0][4].imshow(intensity_shift(tr1_data[0]), cmap=\"grey\")\n",
    "axs[0][4].set_title('Intensity Shift')\n",
    "axs[1][0].imshow(tr2_data[0], cmap=\"grey\")  # Original\n",
    "axs[1][0].set_title('Original T2')\n",
    "axs[1][1].imshow(add_gaussian_noise(tr2_data[0]), cmap=\"grey\")\n",
    "axs[1][1].set_title('Gaussian Noise')\n",
    "axs[1][2].imshow(intensity_gradient(tr2_data[0]), cmap=\"grey\")\n",
    "axs[1][2].set_title('Biased Magnetic Field')\n",
    "axs[1][3].imshow(random_contrast(tr2_data[0]), cmap=\"grey\")\n",
    "axs[1][3].set_title('Randomized Contrast')\n",
    "axs[1][4].imshow(intensity_shift(tr2_data[0]), cmap=\"grey\")\n",
    "axs[1][4].set_title('Intensity Shift')\n",
    "\n",
    "for ax in axs:\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = (1, 2)\n",
    "fig, axs = plt.subplots(1,4)\n",
    "\n",
    "axs[0].imshow(array_to_img(t1_images[0]), cmap='grey')\n",
    "axs[1].imshow(tf.image.adjust_brightness(array_to_img(t1_images[0]), delta=0.5))\n",
    "axs[2].imshow(tf.image.stateless_random_brightness(array_to_img(t1_images[0]),0.2,seed = (1, 2)), cmap='grey')\n",
    "axs[3].imshow(array_to_img(t2_images[0]), cmap='grey')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions & Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "def cycle_loss(real_image, cycled_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return 10.0 * loss\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return 0.5 * loss\n",
    "\n",
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    # Initialization of Objects\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super(InstanceNormalization, self).__init__() # calling parent's init\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.scale = self.add_weight(\n",
    "            name='scale',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer=tf.random_normal_initializer(1., 0.02),\n",
    "            trainable=True)\n",
    "        self.offset = self.add_weight(\n",
    "            name='offset',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "    \n",
    "    def call(self, x):\n",
    "        # Compute Mean and Variance, Axes=[1,2] ensures Instance Normalization\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "        normalized = (x - mean) * inv\n",
    "        return self.scale * normalized + self.offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling and Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_norm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    # Add Conv2d layer\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                      kernel_initializer=initializer, use_bias=False))\n",
    "    # Add Normalization layer\n",
    "    if apply_norm:\n",
    "        result.add(InstanceNormalization())\n",
    "    # Add Leaky Relu Activation\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    # Add Transposed Conv2d layer\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                                               kernel_initializer=initializer, use_bias=False))\n",
    "    # Add Normalization Layer\n",
    "    result.add(InstanceNormalization())\n",
    "    # Conditionally add Dropout layer\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "    # Add Relu Activation Layer\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet Generator is a combination of Convolution + Transposed Convolution Layers\n",
    "def unet_generator():\n",
    "    \n",
    "    down_stack = [\n",
    "        downsample(64, 4, False),\n",
    "        downsample(128, 4),\n",
    "        downsample(256, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4)\n",
    "        \n",
    "        # downsample(64, 4, False), # (bs, 16, 16, 64)\n",
    "        # downsample(128, 4), # (bs, 8, 8, 128)\n",
    "        # downsample(128, 4), # (bs, 4, 4, 128)\n",
    "        # downsample(128, 4), # (bs, 2, 2, 128)\n",
    "        # downsample(128, 4) # (bs, 1, 1, 128)\n",
    "    ]\n",
    "    up_stack = [\n",
    "        upsample(512, 4, True),\n",
    "        upsample(512, 4, True),\n",
    "        # upsample(512, 4, True),\n",
    "        upsample(512, 4),\n",
    "        upsample(256, 4),\n",
    "        upsample(128, 4),\n",
    "        upsample(64, 4)\n",
    "        \n",
    "        # upsample(128, 4, True), # (bs, 2, 2, 256)\n",
    "        # upsample(128, 4, True), # (bs, 4, 4, 256)\n",
    "        # upsample(128, 4), # (bs, 8, 8, 256)\n",
    "        # upsample(64, 4) # (bs, 16, 16, 128)\n",
    "    ]\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh') # (bs, 32, 32, 1)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "    x = inputs\n",
    "    # Downsampling through the model\n",
    "    \n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    \n",
    "    skips = reversed(skips[:-1])\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = concat([x, skip])\n",
    "        \n",
    "    x = last(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g = unet_generator()\n",
    "generator_f = unet_generator()\n",
    "\n",
    "generator_g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminators only contain Convolutional Layers and no Transposed Convolution is not used \n",
    "def discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    # add input layer of size (32, 32, 1)\n",
    "    inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 1], name='input_image')\n",
    "    x = inp\n",
    "    \n",
    "    # add downsampling step here\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 16, 16, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 8, 8, 128)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "    \n",
    "    # add a padding layer here\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 10, 10, 128)\n",
    "    \n",
    "    # implement a concrete downsampling layer here\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1) \n",
    "    # conv = tf.keras.layers.Conv2D(256, 4, strides=1, kernel_initializer=initializer,\n",
    "    #                               use_bias=False)(zero_pad1) # (bs, 7, 7, 256)\n",
    "    norm1 = InstanceNormalization()(conv)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "    \n",
    "    # apply zero padding layer\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 9, 9, 256)\n",
    "    \n",
    "    # add a last pure 2D Convolution layer\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 6, 6, 1)\n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_x = discriminator()\n",
    "discriminator_y = discriminator()\n",
    "\n",
    "discriminator_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_t2_img_data = generator_g(sample_t1_data)\n",
    "to_t1_img_data = generator_f(sample_t2_data)\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "imgs = [sample_t1_data, to_t2_img_data, sample_t2_data, to_t1_img_data]\n",
    "title = ['T1_Img_data', 'To T2_Img_data', 'T2_Img_data', 'To T1_Img_data']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(imgs[i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = TEMP_FOLDER +\"Trained_Model\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model1, test_input1, model2, test_input2, epoch):\n",
    "    prediction1 = model1(test_input1)\n",
    "    prediction2 = model2(test_input2)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    display_list = [test_input1[0], prediction1[0], test_input2[0], prediction2[0]]\n",
    "    title = ['Input Image', 'Predicted Image', 'Input Image', 'Predicted Image']\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i].numpy()[:, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(TEMP_FOLDER +'image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y\n",
    "        # Generator F translates Y -> X\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "        \n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "        \n",
    "        # same_x and same_y are used for identity loss.\n",
    "        same_x = generator_f(real_x, training=True)\n",
    "        same_y = generator_g(real_y, training=True)\n",
    "        \n",
    "        disc_real_x = discriminator_x(real_x, training=True)\n",
    "        disc_real_y = discriminator_y(real_y, training=True)\n",
    "        \n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "        \n",
    "        # calculate the loss\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "        \n",
    "        total_cycle_loss = cycle_loss(real_x, cycled_x) + cycle_loss(real_y, cycled_y)\n",
    "        \n",
    "        # Total generator loss = BCE loss + cycle loss + identity loss\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "        \n",
    "        # Discriminator's loss\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "        \n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
    "    \n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
    "    \n",
    "    # Apply the gradients to the optimizer\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
    "    \n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    for image_x, image_y in tf.data.Dataset.zip((tr1, tr2)):\n",
    "        train_step(image_x, image_y)\n",
    "    generate_images(generator_g, sample_t1_data, generator_f, sample_t2_data, epoch)\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print('Saving checkpoint for epoch', epoch, 'at', ckpt_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = TEMP_FOLDER + 'cyclegan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob( TEMP_FOLDER + 'image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image', 'Expected Image']\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i].numpy()[:, :, 0] * 0.5 + 0.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "for inp in tr1.take(5):\n",
    "    test_model(generator_g, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model_pkl', 'wb') as files:\n",
    "#     pickle.dump(model, files)\n",
    "\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir ./logs/\n",
    "\n",
    "tf.saved_model.save( generator_g, './Output/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsflow-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
